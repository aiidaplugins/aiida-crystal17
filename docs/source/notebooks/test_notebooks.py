"""Test documentation notebooks."""
import io
import logging
import os
import subprocess

import pytest

logger = logging.getLogger(__name__)


@pytest.mark.cry17_doc_notebooks
@pytest.mark.parametrize(
    "filename",
    (
        "calc_main.ipynb",
        "calc_basic.ipynb",
        "calc_main_immigrant.ipynb",
        "workflow_base.ipynb",
    ),
)
def test_notebook(pytestconfig, db_test_app, filename):
    """Execute Jupyter Notebook, using a clean AiiDA database/profile, and test its output is as expected.

    Can be executed by: ``pytest --cry17-nb-tests --log-cli-level=info``
    """
    from pytest_notebook.nb_regression import NBRegressionFixture
    from pytest_notebook.plugin import gather_config_options

    kwargs, other_args = gather_config_options(pytestconfig)

    nb_regression = NBRegressionFixture(**kwargs)
    nb_regression.diff_replace = (
        (
            "/cells/*/outputs/*/text",
            "\\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\\b",
            "<UUID>",
        ),
        (
            "/cells/*/outputs/*/data/text",
            "\\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\\b",
            "<UUID>",
        ),
        ("/cells/*/outputs/*/text", "[-/|\\\\]\b", ""),
        (
            "/cells/*/outputs/*/text",
            "postgres:\\s+Connected as.*\n",
            "postgres:    Connected as <ADDRESS>",
        ),
        ("/cells/*/outputs/*/text", "repository:\\s+/.+\n", "repository:  <DIRPATH>"),
        (
            "/cells/*/outputs/*/text",
            "Daemon is running as PID.+\n",
            "Daemon is running as <PID>\n",
        ),
        ("/cells/*/outputs/*/text", "\\d+s\\sago", "XXs ago"),
        (
            "/cells/*/outputs/*/text",
            "(ctime|mtime)\\s+\\d{2,4}-\\d{1,2}-\\d{1,2}.+\n",
            "(c/m)time <DATETIME>\n",
        ),
        (
            "/cells/*/outputs/*/text",
            "time an entry changed state\\:.+\n",
            "time an entry changed state: <TIME>\n",
        ),
        (
            "/cells/*/outputs/*/text",
            "\\d{2,4}-\\d{1,2}-\\d{1,2}\\s\\d{1,2}:\\d{1,2}:\\d{1,2}",
            "<DATETIME>",
        ),
        (
            "/cells/*/outputs/*/data/text",
            "\\'remote_workdir\\'\\:\\s*\\'[\\_\\/a-zA-Z0-9]+\\'",
            "'remote_workdir': '<DIRPATH>'",
        ),
        (
            "/cells/*/outputs/*/data/text",
            "\\'\\_aiida_hash\\'\\:\\s*\\'[a-z0-9]+\\'",
            "'_aiida_hash': '<HASH>'",
        ),
        (
            "/cells/*/outputs/*/data/text",
            "\\<graphviz.dot.Digraph at .+\\>",
            "<graphviz.dot.Digraph>",
        ),
        (
            "/cells/*/outputs/*/data/image/svg+xml",
            "\\<\\!\\-\\-\\sGenerated\\sby\\sgraphviz\\sversion.*\\-\\-\\>",
            "<!-- Generated by graphviz version XXX -->",
        ),
    )

    from aiida.cmdline.utils.common import get_env_with_venv_bin

    # This environmental variable propagates in the jupyter kernel,
    # so that the test aiida database/profile is used.
    os.environ["AIIDA_PATH"] = db_test_app.environment.config_dir

    # We don't actually need to start a daemon, because ``aiida.engine.run`` creates its own.
    # However, for `verdi status` and `verdi process list`, we then get warning messages.
    curr_env = get_env_with_venv_bin()
    output = subprocess.check_output(
        ["verdi", "daemon", "start"], env=curr_env, stderr=subprocess.STDOUT
    )
    logger.info(output)

    try:
        source_dir = os.path.abspath(os.path.dirname(__file__))
        with io.open(os.path.join(source_dir, filename), "r+") as handle:
            nb_regression.check(handle)
    finally:
        output = subprocess.check_output(
            ["verdi", "daemon", "stop"], env=curr_env, stderr=subprocess.STDOUT
        )
        logger.info(output)
